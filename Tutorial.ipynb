{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background on VAEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vae](figures/vae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pmb{z} \\sim \\mathcal{N}(\\pmb{\\mu}, \\pmb{\\sigma}) \\Longleftrightarrow \\pmb{z} = \\pmb{\\mu} + \\pmb{\\sigma} \\odot \\pmb{\\varepsilon}, \\quad \\pmb{\\varepsilon} \\sim \\mathcal{N}(\\pmb{0}, \\pmb{I})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{D}_{\\text{KL}}\\left( q_{\\phi}(\\pmb{z} \\mid \\pmb{x}^i) \\Vert p_{\\theta}(\\pmb{z} \\mid \\pmb{x}^i) \\right) = \\int_{\\pmb{z}} q_{\\phi}(\\pmb{z} \\mid \\pmb{x}^{i}) \\log \\frac{q_{\\phi} (\\pmb{z} \\mid \\pmb{x}^i)}{p_{\\theta}(\\pmb{z} \\mid \\pmb{x}^i)} \\, d\\pmb{z} \\\\ \n",
    "= \\int_{\\pmb{z}} q_{\\phi}(\\pmb{z} \\mid \\pmb{x}^i) \\log{q_{\\phi}(\\pmb{z} \\mid \\pmb{x}^i)} \\, d\\pmb{z} - \\int_{\\pmb{z}} q_{\\phi}(\\pmb{z} \\mid \\pmb{x}^i) \\log{p_{\\theta}(\\pmb{x}^i \\mid \\pmb{z})} \\, d\\pmb{z}- \\int_{\\pmb{z}} q_{\\phi}(\\pmb{z} \\mid \\pmb{x}^i) \\log{ p_{\\theta}(\\pmb{z}) \\, d\\pmb{z}}+ \\int_{\\pmb{z}} q_{\\phi}(\\pmb{z} \\mid \\pmb{x}^i) \\log{p_{\\theta}(\\pmb{x}^i) \\, d\\pmb{z}} = \\\\\n",
    "\\mathbb{D}_{\\text{KL}}\\left(q_{\\phi}(\\pmb{z} \\mid \\pmb{x}^i) \\Vert p_{\\theta}(\\pmb{z}) \\right)- \\mathbb{E}_{q_{\\phi}(\\pmb{z} \\mid \\pmb{x}^i)} \\left[ \\log p_{\\theta}(\\pmb{x}^i \\mid \\pmb{z}) \\right] + \\log p_{\\theta}(\\pmb{x}^i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we have the Bayes identity $p_{\\theta}(\\pmb{z} \\mid \\pmb{x}^{i}) = p_{\\theta}(\\pmb{x}^i \\mid \\pmb{z}) p_{\\theta}(\\pmb{z}) / p_{\\theta}(\\pmb{x}^i)$ and $\\int_{\\pmb{z}} q_{\\phi}(\\pmb{z} \\mid \\pmb{x}^i) \\, d\\pmb{z} = 1$.\n",
    "Rearranging, we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\log \\, p_{\\theta}(\\pmb{x}^i) = \\mathbb{D}_{\\text{KL}}\\left( q_{\\phi}(\\pmb{z} \\mid \\pmb{x}^i) \\Vert p_{\\theta}(\\pmb{z} \\mid \\pmb{x}^i) \\right)+ \\underset{\\texttt{ELBO}}{\\underbrace{\\mathbb{E}_{q_{\\phi}(\\pmb{z} \\mid \\pmb{x}^i)} \\left[ \\log p_{\\theta}(\\pmb{x}^i \\mid \\pmb{z}) \\right] - \\mathbb{D}_{\\text{KL}}\\left(q_{\\phi}(\\pmb{z} \\mid \\pmb{x}^i) \\Vert p_{\\theta}(\\pmb{z}) \\right)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is it called ELBO?\n",
    "$$\n",
    "\\log p_{\\theta}(\\pmb{x}^i) \\geq \\mathbb{E}_{q_{\\phi}(\\pmb{z} \\mid \\pmb{x}^i)} \\left[ \\log p_{\\theta}(\\pmb{x}^i \\mid \\pmb{z}) \\right] - \\mathbb{D}_{\\text{KL}}\\left(q_{\\phi}(\\pmb{z} \\mid \\pmb{x}^i) \\Vert p_{\\theta}(\\pmb{z}) \\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, absolute_import, print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "log_interval = 10\n",
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc21 = nn.Linear(400, latent_dim)\n",
    "        self.fc22 = nn.Linear(400, latent_dim)\n",
    "        self.fc3 = nn.Linear(latent_dim, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function_vanilla(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, loss_function):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch, loss_function, tag):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(batch_size, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         'results/{}/reconstruction_'.format(tag) + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = 'vanilla'\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch, loss_function_vanilla)\n",
    "    test(epoch, loss_function_vanilla, tag)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(64, latent_dim).to(device)\n",
    "        sample = model.decode(sample).cpu()\n",
    "        save_image(sample.view(64, 1, 28, 28),\n",
    "                       'results/{}/sample_'.format(tag) + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_KLD_weights(model):\n",
    "  def KLD(mu, logvar):\n",
    "    with torch.no_grad():\n",
    "      return -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp(),\n",
    "                             dim=0,\n",
    "                             keepdim = True)\n",
    "  \n",
    "  model.eval()\n",
    "  total_KLD = np.zeros((1,latent_dim), dtype=np.float32)\n",
    "  with torch.no_grad():\n",
    "    for i, (data, _) in enumerate(test_loader):\n",
    "      data = data.to(device)\n",
    "      recon_batch, mu, logvar = model(data)\n",
    "      batch_KLD = KLD(mu, logvar)\n",
    "      total_KLD += batch_KLD.cpu().numpy()\n",
    "      total_KLD /= 2.0\n",
    "\n",
    "  return total_KLD, torch.norm(model.fc3.weight.data, dim=0).cpu().numpy()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_KLD, weights = get_KLD_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(latent_dim), t_KLD.squeeze())\n",
    "plt.show()\n",
    "plt.bar(np.arange(latent_dim), weights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function_beta_scheduled(recon_x, x, mu, logvar, epoch):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    beta = 1.0 * epoch/epochs\n",
    "    \n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + beta * KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "tag = 'beta_scheduled'\n",
    "for epoch in range(1, epochs + 1):  \n",
    "    loss_function_beta = partial(loss_function_beta_scheduled, epoch=epoch)\n",
    "    train(epoch, loss_function_beta)\n",
    "    test(epoch, loss_function_beta, tag)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(64, latent_dim).to(device)\n",
    "        sample = model.decode(sample).cpu()\n",
    "        save_image(sample.view(64, 1, 28, 28),\n",
    "                       'results/{}/sample_'.format(tag) + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_KLD, weights = get_KLD_weights(model)\n",
    "plt.bar(np.arange(latent_dim), t_KLD.squeeze())\n",
    "plt.show()\n",
    "plt.bar(np.arange(latent_dim), weights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sfb](figures/sfb2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function_soft_bits(recon_x, x, mu, logvar, gamma_factor):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    \n",
    "    KLD = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp(), dim=0)\n",
    "\n",
    "    return BCE/batch_size + torch.sum(gamma_factor * KLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, prev_gamma=None):\n",
    "    def KLD(mu, logvar):\n",
    "        with torch.no_grad():\n",
    "            return -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp(),\n",
    "                               dim=0,\n",
    "                               keepdim = True)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    lambda_per_dim = 0.5\n",
    "    information_threshold = 0.1\n",
    "    gamma_rate = 0.1\n",
    "    \n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            KL_per_dim = KLD(mu, logvar)\n",
    "\n",
    "            factor_1 = torch.le(KL_per_dim,\n",
    "                                (1-information_threshold) * lambda_per_dim)\n",
    "            factor_1 = torch.where(factor_1,\n",
    "                                   torch.ones_like(KL_per_dim) * (1. - gamma_rate),\n",
    "                                   torch.ones_like(KL_per_dim))\n",
    "            factor_2 = torch.ge(KL_per_dim,\n",
    "                                (1+information_threshold) * lambda_per_dim)\n",
    "            factor_2 = torch.where(factor_2,\n",
    "                                   torch.ones_like(KL_per_dim) * (1. + gamma_rate),\n",
    "                                   torch.ones_like(KL_per_dim))\n",
    "            factor = factor_1 * factor_2\n",
    "            gamma_factor = factor.to(device) * prev_gamma\n",
    "            gamma_factor = torch.clamp(gamma_factor, 0., 1.)\n",
    "        \n",
    "        \n",
    "        loss = loss_function_soft_bits(recon_batch, data, mu, logvar, \n",
    "                                       gamma_factor)\n",
    "#         import pdb; pdb.set_trace()\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item()*batch_size / len(data)) + '\\tGamma: ',gamma_factor.norm().item())\n",
    "        prev_gamma = gamma_factor\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "    return gamma_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "tag = 'soft_bits'\n",
    "# prev_gamma = torch.ones((1, latent_dim)).to(device)\n",
    "# prev_gamma *= 0.01\n",
    "prev_gamma = torch.rand((1, latent_dim)).to(device)\n",
    "prev_gamma.require_grad = False\n",
    "for epoch in range(1, epochs + 1):  \n",
    "    next_gamma = train(epoch, prev_gamma)\n",
    "    soft_loss = partial(loss_function_soft_bits, gamma_factor=prev_gamma)\n",
    "    test(epoch, soft_loss, tag)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(64, latent_dim).to(device)\n",
    "        sample = model.decode(sample).cpu()\n",
    "        save_image(sample.view(64, 1, 28, 28),\n",
    "                       'results/{}/sample_'.format(tag) + str(epoch) + '.png')\n",
    "    prev_gamma = next_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_KLD, weights = get_KLD_weights(model)\n",
    "plt.bar(np.arange(latent_dim), t_KLD.squeeze())\n",
    "plt.show()\n",
    "plt.bar(np.arange(latent_dim), weights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "@inproceedings{kingma2014semi,\n",
    "  title={Semi-supervised learning with deep generative models},\n",
    "  author={Kingma, Durk P and Mohamed, Shakir and Rezende, Danilo Jimenez and Welling, Max},\n",
    "  booktitle={Advances in neural information processing systems},\n",
    "  pages={3581--3589},\n",
    "  year={2014}\n",
    "}\n",
    "\n",
    "@inproceedings{dehban2017deep,\n",
    "  title={A deep probabilistic framework for heterogeneous self-supervised learning of affordances},\n",
    "  author={Dehban, Atabak and Jamone, Lorenzo and Kampff, Adam R and Santos-Victor, Jos{\\'e}},\n",
    "  booktitle={2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids)},\n",
    "  pages={476--483},\n",
    "  year={2017},\n",
    "  organization={IEEE}\n",
    "}\n",
    "\n",
    "@article{higgins2017beta,\n",
    "  title={beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework.},\n",
    "  author={Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},\n",
    "  journal={ICLR},\n",
    "  volume={2},\n",
    "  number={5},\n",
    "  pages={6},\n",
    "  year={2017}\n",
    "}\n",
    "\n",
    "@article{bowman2015generating,\n",
    "  title={Generating sentences from a continuous space},\n",
    "  author={Bowman, Samuel R and Vilnis, Luke and Vinyals, Oriol and Dai, Andrew M and Jozefowicz, Rafal and Bengio, Samy},\n",
    "  journal={arXiv preprint arXiv:1511.06349},\n",
    "  year={2015}\n",
    "}\n",
    "\n",
    "@inproceedings{\n",
    "he2018lagging,\n",
    "title={Lagging Inference Networks and Posterior Collapse in Variational Autoencoders},\n",
    "author={Junxian He and Daniel Spokoyny and Graham Neubig and Taylor Berg-Kirkpatrick},\n",
    "booktitle={International Conference on Learning Representations},\n",
    "year={2019},\n",
    "url={https://openreview.net/forum?id=rylDfnCqF7},\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
